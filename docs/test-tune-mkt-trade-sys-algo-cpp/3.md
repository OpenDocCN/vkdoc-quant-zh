# 三、优化问题

## 正则化线性模型

如果我只能让这本书的读者有一个想法，那就是:*你的指标的强度比用它们来指示交易的预测模型的强度重要得多。*这些年来我见过的一些最好的、最稳定的、最赚钱的交易系统，都是使用简单的线性或接近线性的模型，以高质量的指标作为输入。我也见过太多的人向一些现代的、高度复杂的非线性模型提供边际指标，徒劳地希望该模型将奇迹般地克服*垃圾进、垃圾出*规则。它不会发生。当我在开发一个新的交易系统时，我首先转向线性模型，只有当我看到明显的优势时，才转向非线性模型。

与复杂的非线性模型相比，在基于预测模型的交易系统中使用线性模型有很多优点。

*   线性模型不太可能过度拟合训练数据。因此，*训练偏差*被最小化。这个问题在第 121 页开始的部分有更详细的论述。

*   线性模型比许多或大多数非线性模型更容易理解。理解指标值与交易决策的关系是预测模型的一个非常有价值的属性。

*   线性模型的训练速度通常比非线性模型快。在第七章中，我们将探索需要频繁重新训练的强大测试算法，因此快速训练是一个主要优势。

*   很容易将线性模型转换成非线性模型，而不会严重破坏刚刚列出的特性。这将在第 67 页讨论。

*   随着算法复杂性的适度增加，很容易惩罚过度复杂/强大的线性模型，这是一个重要但经常被忽视的正确训练的一部分，称为*正则化*。

### 正则化模型概述

正如从第 121 页开始的部分将详细讨论的那样，当模型错误地将随机噪声与真实的、可重复的模式混为一谈时，预测模型的设计和训练中就会出现一个常见而严重的问题。这叫做*过拟合*。因为根据定义，噪声不会重复，一个过度拟合的模型在投入使用时会表现不佳。

普通的线性模型比大多数非线性模型更不容易过度拟合，尤其是那些极其复杂和强大的模型。但是，即使普通的线性模型也可能过度拟合训练数据，这通常是因为使用了太多的预测器。至少有两种常见且适度有效的方法来处理由于预测器数量过多而导致的过拟合问题。

*   *减少预测器的数量*:最常用的方法是*向前逐步选择*。选择一个最有效的预测值。然后，在第一个预测因子存在的情况下，选择一个增加最大预测能力的预测因子。然后选择第三个，依此类推。这种方法的一个严重问题是很难找到第一个单独的预测器。在大多数应用中，是几个预测器的相互作用提供了动力；没有一个单一的预测器做得很好。事实上，可能是 *A* 和 *B* 一起做了一个神话般的工作，而其中任何一个都是毫无价值的。但如果 *C* 恰好表现一般， *C* 可能会先被选中，结果是 *A* 和 *B* 都没有进入比赛，这个优秀的组合也就失去了。还有其他更高级的变异，如逆向选择或子集保留。这些在我的书*c++ 中的数据挖掘算法*中有详细讨论。然而，每种方法都有自己的问题。

*   *将线性回归方程中的系数向零收缩*，远离它们的“最佳”最小二乘值。这可能非常有用，因为它让我们保留所有相关的预测器和它们的联合关系信息，同时降低它们学习随机噪声以及更显著的真实模式的能力。但这不是一项微不足道的任务。

有效的模型设计和训练(线性或非线性)的目标是执行这两个修正中的一个或(通常)两个。有许多方法可以做到这一点，其中大多数都涉及到对模型的复杂性施加惩罚，这一过程被称为*正则化*。区分各种方法的是复杂性的定义和相关惩罚的性质。当应用于线性模型时，此处显示的方法特别强大，因为它可以根据用户的判断进行一种或两种修复，并且它以一种易于理解和快速训练的方式进行。此外，有一个简单的交叉验证方案，让我们优化复杂性降低超参数。它真的很漂亮。

首先我们必须设计一些符号。不失一般性，所有后续开发将假设所有预测值 *x 已被标准化为具有零均值和单位方差*。这极大地简化了相关的方程以及相关的计算机代码。如果需要，简单的代数运算可以恢复原始变量的系数。

*   N -案例的数量。

*   K -预测变量的数量。

*   *x*<sub>*ij*</sub>——案例 *i* 的预测值 *j* 。

*   ***x***<sub>*I*</sub>-预测向量( *K* long)为例 *i* 。这是一个列向量，是表示所有 *j* 的集合*x*<sub>*ij*</sub>的一种方便的表示法。

*   *y*<sub>*I*</sub>——事例 *i* 的目标变量。

*   β -方程 3-1 表示的线性模型中的 *K* 系数。这是一个列向量。

*   β<sub>0</sub>——方程 3-1 表示的线性模型中的标量常数。

*   α -控制正则化的*类型*的范围从 0 到 1 的常数。

*   λ -控制正则化的*度*的非负常数。

基本的线性模型认为目标变量的期望值等于预测值的加权组合，加上一个常数。这在方程 3-1 中以矢量形式显示。

![$$ \widehat{y}={\beta}_0+{x}^T\beta $$](img/474239_1_En_3_Chapter_TeX_Equ1.png)

(3-1)

我们已经假设预测值已经标准化为零均值和单位方差。在这种情况下，β <sub>0</sub> 等于目标的平均值。(这一简单结果的推导在许多标准统计学文本中都有说明。)如果我们假设目标变量*也已经标准化*，我们可以在开发和编程中获得更多的简单性。我们由此知道β <sub>0</sub> = 0，因此在所有后续工作中可以忽略它。在这种情况下，我们预测目标的标准化值。要获得原始目标的预测值，只需进行非标准化:乘以标准偏差，然后加上平均值。即使有了这个额外的假设，所有原始值的系数和β <sub>0</sub> 也很容易用基本代数得到。

找到β权重的最佳值的传统方法是计算最小化均方误差的那些值，即每个预测值*yˇ*<sub>*I*</sub>和真实目标值 *y* <sub>*i*</sub> 之间的均方差。但是在我们的正则化版本中，我们给误差增加了一个惩罚项，惩罚是β权重集的函数。这显示在方程式 3-2 中。在这个等式中，乘数 2 可以被吸收到λ或 *P* <sub>*α*</sub> ()中，但以这种方式显示是为了澄清一些中间推导，我们在这里不做介绍，因为我们的重点将放在对模型编程至关重要的等式上。要了解全部细节，请参阅 Friedman、Hastie 和 Tibshirani 的优秀论文“通过坐标下降的广义线性模型的正则化路径”(*统计软件杂志*，2010 年 1 月)。注意，λ控制惩罚项的影响，如果λ = 0，我们有普通的最小二乘解。将 *α* 的下标应用于罚函数 *P* 来阐明它控制罚函数性质的事实。还要注意，方程 3-2 是那篇论文中误差的两倍，没有实际后果。

![$$ RegErr=\frac{1}{N}\sum \limits_{i=1}^N{\left({y}_i-{x}^T\beta \right)}²+2\lambda \kern0.125em {P}_{\alpha}\left(\beta \right) $$](img/474239_1_En_3_Chapter_TeX_Equ2.png)

(3-2)

罚函数 *P* <sub>*α*</sub> 是权重向量的二范数(平方和)和一范数(绝对值和)的加权和，相对权重由 *α* 参数确定。这显示在方程式 3-3 中。

![$$ {P}_{\alpha}\left(\beta \right)=\sum \limits_{j=1}^K\left[\frac{\left(1-\alpha \right)}{2}{\beta}_j²+\alpha |{\beta}_j|\right] $$](img/474239_1_En_3_Chapter_TeX_Equ3.png)

(3-3)

*α* 的值对罚函数的性质有深远的影响，该值的范围可以从 0 到 1。这两个极端值有一个共同的名字，许多开发人员都很熟悉。当 *α* = 0 时，我们有*岭回归*，当 *α* = 1 时，我们有*套索*。这两个极端模型之间的差异最好通过考虑当存在高度相关的预测因子时会发生什么来说明。岭回归倾向于给相关集合中的所有预测因子分配大致相等的权重，从所有预测因子中提取大致相等的贡献。事实上，如果有一组 *m* 完全相关(归一化后相同)的预测值，岭回归将为每个预测值分配一个β权重，该权重等于 1/ *m* 乘以在没有其他预测值的情况下分配给其中一个预测值的权重。

套索( *α* = 1)对一组高度相关的变量做出相反的反应。它倾向于挑选对模型最有用的一个，给它分配一个相对较大的权重，给相关集合的其他成员分配零权重，实际上是将它们从模型中移除，而不是给所有成员分配较小的、相似的权重。

*α* = 1 的一个潜在问题是，如果碰巧有两个或更多的预测器完全相关，套索就会失去判断哪个是最好的想法，因为它们都同样有用。训练算法在数值上变得不稳定。由于这个原因，除非你确信数据中不存在这种退化，否则如果你想使用套索模型，你应该将 *α* 设置为非常接近 1 但不完全是 1 的值。这个模型将几乎等同于一个真正的套索，但不会因为完美或接近完美的相关性而不稳定。

在大多数金融交易开发中，有大量的预测器以“墙上的意大利面条”的方式扔向模型，通常最好将 *α* 设置为 0 到 1 之间的一个值，以达到最佳效果。对于任何固定的λ，零系数(从模型中排除的变量)的数量随着 *α* 从零到一单调增加。当 *α* = 0 时，所有变量都包括在内，然后对于更大的 *α* 值，它们倾向于一个接一个地退出(它们的β权重变为零)。以这种方式，开发者可以设置 *α* 的值来支持期望的稀疏度。

在将这里描述的模型与普通的线性回归进行比较时，读者应该记住三件事:

*   当我们这样惩罚模型时，我们得到的解不再是最小二乘解。计算的β权重将产生超过普通线性回归的均方误差。在大多数实际应用中，这是一件好事，因为它产生了更好的泛化能力。这就是这种方法的全部意义！然而，从表面上看，这似乎是违反直觉的，好像我们在故意削弱这个模型。但这正是我们正在做的，以减少它错误地学习随机噪声的能力。

*   我们应该对这个模型如何处理强相关的预测值感到特别高兴。普通的线性回归通常对这种情况有可怕的反应，将一些系数放大到巨大的正值，然后通过将其他系数放大到巨大的负值来进行补偿，使一个相关变量与另一个相关变量保持微妙的平衡关系。

*   这种正则化模型通常找到候选预测值的一个子集，通常是一个小的子集，就像普通逐步包含的情况一样。但它的方法非常不同，远远优于逐步包含。后者采取有序的全有或全无的方法；一旦一个变量被包含，它将永远存在。但是正则化的线性模型是逐渐运行的，缓慢地收敛于预测因子的理想子集。在其他变量存在的情况下，变量的值会时好时坏。这使得最终子集更有可能是真正最优的。

### 保证收敛的β调整

有一个简单的公式，根据该公式，给定训练数据，连同超参数λ和 *α* ，我们可以有效地计算出调整后的β权重，从而降低等式 3-2 中所示的误差标准。在所有实际条件下，该误差准则具有单个局部最小值，该局部最小值也是全局最小值。因此，即使对于大问题，简单的权重旋转也能保证收敛，通常非常快。在这一节中，我们将介绍这一调整公式，省略了在前面引用的论文中可以找到的许多推导细节。我们将很快看到如何使用这个公式来实现一个高效稳定的训练算法。

首先将模型的*残差*定义为其预测误差，如方程 3-4 所示。

![$$ {r}_i={y}_i-{\widehat{y}}_i $$](img/474239_1_En_3_Chapter_TeX_Equ4.png)

(3-4)

为每个预测值 *j* 定义一个我称之为*自变量* <sub>*j*</sub> 的项，如等式 3-5 所示。这是计算的缓慢部分，因为它需要对所有情况下的乘积求和。定义软阈值算子 *S* ()，如公式 3-6 所示。然后，减少误差标准的β <sub>*j*</sub> 的新值由等式 3-7 给出。

![$$ argumen{t}_j=\frac{1}{N}\sum \limits_{i=1}^N{x}_{ij}{r}_i+{\beta}_j $$](img/474239_1_En_3_Chapter_TeX_Equ5.png)

(3-5)

![$$ S\left(z,g\right)=\mid {\displaystyle \begin{array}{ll}z-g&amp; \mathrm{if}\ z&gt;0,g&lt;z\\ {}z+g&amp; \mathrm{if}\ z&lt;0,g&lt;-z\\ {}0&amp; \mathrm{otherwise}\end{array}} $$](img/474239_1_En_3_Chapter_TeX_Equ6.png)

(3-6)

![$$ {\widehat{\beta}}_j=\frac{S\left( argumen{t}_j,\lambda \alpha \right)}{1+\lambda \left(1-\alpha \right)} $$](img/474239_1_En_3_Chapter_TeX_Equ7.png)

(3-7)

### 差异案例加权

在某些应用程序中(虽然在市场交易应用程序中并不常见)，将一些案例评定为比其他案例更重要，从而指导训练算法更加关注减少重要案例的错误，这可能是有用的。上一节中展示的测试版更新公式很容易修改来实现这一功能。

让 *N* 个案例权重被表示为*w*<sub>I</sub>，其中这些权重总和为 1。等式 3-8 给出了软阈值算子的自变量，等式 3-9 给出了更新后的β权重。

![$$ argumen{t}_j=\sum \limits_{i=1}^N\ {w}_i{x}_{ij}\left({r}_i+{\beta}_j{x}_{ij}\right) $$](img/474239_1_En_3_Chapter_TeX_Equ8.png)

(3-8)

![$$ {\widehat{\beta}}_j=\frac{S\left( argumen{t}_j,\lambda \alpha \right)}{\sum \limits_{i=1}^N\ {w}_i\kern0.125em {x}_{ij}²+\lambda \left(1-\alpha \right)} $$](img/474239_1_En_3_Chapter_TeX_Equ9.png)

(3-9)

感兴趣的读者最好做一个简单的练习。假设所有权重都等于 1/ *N* ，那么不存在差分加权。解决方程 3-8 简化为方程 3-5 ，方程 3-9 简化为方程 3-7 的问题。如果没有马上看到(剧透预警！)，记住预测因子已经标准化为单位方差了。因此，对于每个 *j* ，所有情况下的总和*x*<sub>*ij*</sub>的平方等于 *N* 。

### 协方差更新的快速计算

如果情况( *N* )比预测值( *K* )多得多，这是市场交易中的常见情况，那么有一个替代公式来计算β权重更新，它比“原始”公式 3-5 和 3-8 快得多。基本公式由公式 3-10 给出。

![$$ argumen{t}_j= Yinne{r}_j-\sum \limits_{k=1}^K Xinne{r}_{jk}{\beta}_k+ Xs{s}_j{\beta}_j $$](img/474239_1_En_3_Chapter_TeX_Equ10.png)

(3-10)

如果不使用差分案例加权，则所有 *j* 、*茵纳*、 *j* 、*欣纳*、<sub>JK、 3-12 由公式 3-11 给出 *Xss* 、*j*、</sub> = 1。这些表达式的推导在前面引用的论文中给出。

![$$ Yinne{r}_j=\frac{1}{N}\sum \limits_{i=1}^N{x}_{ij}\kern0.125em {y}_i $$](img/474239_1_En_3_Chapter_TeX_Equ11.png)

(3-11)

![$$ Xinne{r}_{jk}=\frac{1}{N}\sum \limits_{i=1}^N{x}_{ij}\kern0.125em {x}_{ik} $$](img/474239_1_En_3_Chapter_TeX_Equ12.png)

(3-12)

如果我们使用差分加权，我们需要方程 3-13 、 3-14 和 3-15 。这些推导在引用的论文中没有给出，但是它们很容易从方程 10 开始并遵循非加权步骤得到，记住预测值是标准化的。

![$$ Xs{s}_j=\sum \limits_{i=1}^N{w}_i\kern0.125em {x}_{ij}² $$](img/474239_1_En_3_Chapter_TeX_Equ13.png)

(3-13)

![$$ Yinne{r}_j=\sum \limits_{i=1}^N{w}_i\kern0.125em {x}_{ij}\kern0.125em {y}_i $$](img/474239_1_En_3_Chapter_TeX_Equ14.png)

(3-14)

![$$ Xinne{r}_{jk}=\sum \limits_{i=1}^N{w}_i\kern0.125em {x}_{ij}\kern0.125em {x}_{ik} $$](img/474239_1_En_3_Chapter_TeX_Equ15.png)

(3-15)

注意，等式 3-13 到 3-15 仅取决于训练数据和权重，因此它们可以在训练开始时仅计算一次。而且方程 3-10 ，每次迭代都必须求值，只涉及对 K 项求和，而不是对 N 项求和，当 K < < N 时，节省的时间是巨大的。

#### 预备代码

我们以一些片段开始展示代码，这些片段说明了我们如何准备训练模型的关键部分。封装该模型及其所有训练算法的整个`CoordinateDescent`类的完整源代码在 CDMODEL.CPP 文件中。

程序员将首先调用构造函数，如下所示。这里我们将跳过它的代码，因为它只涉及内存分配和其他简单的内务处理。暂时忽略`nl`参数；这个后面会讨论。其他参数不言自明。

```cpp
CoordinateDescent::CoordinateDescent (
   int nv ,        // Number of predictor variables
   int nc ,        // Number of cases we will be training
   int wtd ,      // Will we be using case weights?  1=Yes, 0=No
   int cu ,        // Use fast covariance updates rather than slow naive method
   int nl           // Number of lambdas we will be using in training
   )

```

在我们构造了一个`CoordinateDescent`对象之后，必须调用一个成员函数来输入训练数据，计算一些准备中的东西。

```cpp
void CoordinateDescent::get_data (
   int istart ,     // Starting index in full database for getting nc cases of training set
   int n ,           // Number of cases in full database (we wrap back to the start if needed)
   double *xx , // Full database (n rows, nvars columns)
   double *yy , // Predicted variable vector, n long
   double *ww  // Case weights (n long) or NULL if no weighting
   )

```

在这个调用中，我们可以在数据集中指定一个起始索引(用于预测值、目标值和可选权重)。构造函数调用(`nc`)中指定的事例数将从索引`istart`开始从`xx`、`yy`和`ww`(如果使用)中获取。如果在获得`nc`病例之前到达数据的结尾，它会绕到数据集的开头。我们稍后会看到这种包装是如何有用的。

`get_data()`例程首先将预测值和目标值保存在私有数组中，然后通过减去平均值并除以标准偏差来标准化它们。这里没有显示这些简单的操作。如果要使用差分加权，权重被缩放为总和为 1(因此用户无需担心这一点)，并且使用等式 3-13 计算`XSSvec`。与重量相关的代码如下:

```cpp
   if (w != NULL) {
      sum = 0.0 ;
      for (icase=0 ; icase<ncases ; icase++) {
         k = (icase + istart) % n ;     // Wrap to start if needed
         w[icase] = ww[k] ;
         sum += w[icase] ;
         }
      for (icase=0 ; icase<ncases ; icase++)
         w[icase] /= sum ;

      for (ivar=0 ; ivar<nvars ; ivar++) {
         xptr = x + ivar ;
         sum = 0.0 ;
         for (icase=0 ; icase<ncases ; icase++)      // Equation 3-13
            sum += w[icase] * xptr[icase*nvars] * xptr[icase*nvars] ;
         XSSvec[ivar] = sum ;
         }
      }

```

如果我们使用快速协方差更新方法，这是当案例多于预测值时的明智做法，我们必须按照上一节所述计算`Yinner`和`Xinner`。注意`Xinner`是一个对称矩阵，但是我们还是保存了整个矩阵。这浪费了非常便宜的存储器，但是更简单的寻址节省了非常昂贵的时间。

在下面的代码中，我们一次处理一个变量。在第一种情况下，通过使用指针`xptr`获得当前变量的偏移量，可以简化寻址。此后，我们只需向下跳一格就可以得到这个变量。

```cpp
      for (ivar=0 ; ivar<nvars ; ivar++) {
         xptr = x + ivar ;
         sum = 0.0 ;           // Do Yinner
         if (w != NULL) {    // Weighted cases
            for (icase=0 ; icase<ncases ; icase++)
               sum += w[icase] * xptr[icase*nvars] * y[icase] ;    // Equation 3-14
            Yinner[ivar] = sum ;
            }
         else {
            for (icase=0 ; icase<ncases ; icase++)
               sum += xptr[icase*nvars] * y[icase] ;                     // Equation 3-11
            Yinner[ivar] = sum / ncases ;
            }

         // Do Xinner
         if (w != NULL) {  // Weighted
            for (jvar=0 ; jvar<nvars ; jvar++) {
               if (jvar == ivar)
                  Xinner[ivar*nvars+jvar] = XSSvec[ivar] ; // Already computed, so use it
               else if (jvar < ivar)                                      // Matrix is symmetric, so just copy
                  Xinner[ivar*nvars+jvar] = Xinner[jvar*nvars+ivar] ;
               else {
                  sum = 0.0 ;
                  for (icase=0 ; icase<ncases ; icase++)
                     sum += w[icase] * xptr[icase*nvars] * x[icase*nvars+jvar] ; // Eq (3-15)
                  Xinner[ivar*nvars+jvar] = sum ;
                  }
               }
            } // If w

         else {  // Unweighted
            for (jvar=0 ; jvar<nvars ; jvar++) {
               if (jvar == ivar)
                  Xinner[ivar*nvars+jvar] = 1.0 ;       // Recall that X is standardized
               else if (jvar < ivar)                              // Matrix is symmetric, so just copy
                  Xinner[ivar*nvars+jvar] = Xinner[jvar*nvars+ivar] ;
               else {
                  sum = 0.0 ;
                  for (icase=0 ; icase<ncases ; icase++)
                     sum += xptr[icase*nvars] * x[icase*nvars+jvar] ;    // Equation 3-12
                  Xinner[ivar*nvars+jvar] = sum / ncases ;
                  }
               }
            } // // Else not weighted
         } // For ivar

```

### Beta 优化流程概述

在前面的几节中，我们看到了对于任何选择的β权重，我们如何计算一个修正值，该值将误差标准降低到唯一的全局最小值。因此，在最简单的层面上，我们可以轮换权重，依次调整每个权重，直到获得令人满意的收敛。但是我们可以更智能地做这件事，利用这样一个事实:一旦β权重变为零，它在后续迭代中倾向于保持为零。这里显示了训练算法的概要，解释如下。稍后会出现更详细的代码。

```cpp
   do_active_only = 0 ;                             // Begin with a complete pass
   for (iter=0 ; iter<maxits ; iter++) {          // Main iteration loop; maxits is for safety only
      active_set_changed = 0 ;                  // Did any betas go to/from 0.0?

      for (ivar=0 ; ivar<nvars ; ivar++) {      // Descend on this beta
         if (do_active_only  &&  beta[ivar] == 0.0)
            continue ;

         [ Compute correction ]
         if (correction != 0.0) {                      // Did this beta change?
            if ((beta[ivar]==0.0 && new_beta != 0.0) || (beta[ivar] != 0.0 && new_beta==0.0))
               active_set_changed = 1 ;
            }

         } // For all variables; a complete pass

      converged = [ Convergence test ] ;

      if (do_active_only) {                            // Are we iterating on the active set only?
         if (converged)                                   // If we converged
            do_active_only = 0 ;                       // We now do a complete pass
         }
      else {                                                   // We just did a complete pass (all variables)
         if (converged  &&  ! active_set_changed)
            break ;
         do_active_only = 1 ;                        // We now do an active-only pass
         }
      } // Outer loop iterations

```

这种训练算法的基本思想是，我们可以通过将大部分精力集中在那些非零的β权重(称为*活动*集)上来节省大量计算工作。粗略地说，我们通过所有的预测，调整每个β权重。过了这一关之后，经常会出现这样的情况，一些测试，也许是许多测试，是零。因此，我们进行额外的传递，只调整那些非零的(活动集)，直到获得收敛。当我们收敛时，我们会遍历所有预测值，以防修正的β权重导致一个或多个β变为零或从零开始。如果没有这样的变化发生，并且我们通过了收敛测试，我们就完成了。否则，我们将返回到仅在活动集中循环。

我们从`do_active_only` *假*开始，以便调整所有预测值。为了安全起见，主迭代循环受到`maxits`的限制，尽管实际上这个限制永远不会达到。我们使用`active_set_changed`来标记是否有任何 beta 权重变为零或从零开始。

`ivar`循环对所有预测器进行一次遍历。如果我们只做活动集，而这个β是零，跳过它。否则，我们计算一个修正的β。如果 beta 发生了变化，我们可以看到变化是从零开始还是到零，如果是这样，我们可以通过设置`active_set_changed`标志来记录。

在我们通过预测器之后，我们执行一个收敛测试。如果我们一直只检查活动集，并且如果我们已经收敛，我们重置`do_active_only`以便下一次我们检查所有预测器。

另一方面，如果我们的最后一遍是对所有预测值的完整检查，获得了收敛，并且活动集没有改变，那么我们就都完成了。否则，我们设置`do_active_only`标志，以便我们回到只关注活动集。

这种专注于活动集的奇特算法只有在有大量零 beta 权重时才有优势。但是，在使用这种模型的应用程序中，情况往往就是这样。此外，在贝塔系数很少或没有为零的情况下，惩罚很少或没有，所以我们不妨使用花哨的版本。

### Beta 优化代码

前一节给出了 beta 优化算法的概要，省略了细节，以便过程的基本逻辑将是清楚的。在本节中，我们将详细介绍整个优化代码。它的名称如下:

```cpp
void CoordinateDescent::core_train (
   double alpha ,            // User-specified alpha (0-1) (0 problem for descending lambda)
   double lambda ,         // Can be user-specified, but usually from lambda_train()
   int maxits ,                  // Maximum iterations, for safety only
   double eps ,               // Convergence criterion, typically 1.e-5 or so
   int fast_test ,              // Convergence via max beta change vs explained variance?
   int warm_start            // Start from existing beta, rather than zero?
   )

```

`alpha` ( *α* )和`lambda` (λ)参数已经见过很多次了。我们使用`maxits`只是为了限制迭代次数，以防止意外挂起。实际上，它会被设置得非常大。`eps`参数控制收敛信号发出前结果的精确度。`fast_test`参数控制使用两个收敛测试(稍后描述)中的哪一个。最后，`warm_start`允许从 beta 权重的当前值开始训练，而不是从零开始(默认)。该例程从一些初始化开始。

```cpp
   S_threshold = alpha * lambda ;        // Threshold for the soft-thresholding S() of Eq (3-6)
   do_active_only = 0 ;                         // Begin with a complete pass
   prior_crit = 1.0e60 ;                          // For convergence test

   if (warm_start) {               // Pick up with current betas?
      if (! covar_updates) {    // If not using covar updates, must recompute residuals
         for (icase=0 ; icase<ncases ; icase++) {
            xptr = x + icase * nvars ;
            sum = 0.0 ;
            for (ivar=0 ; ivar<nvars ; ivar++)
               sum += beta[ivar] * xptr[ivar] ;
            resid[icase] = y[icase] - sum ;
            }
         }
      }

   else {                                         // Not warm start, so initial betas are all zero
      for (i=0 ; i<nvars ; i++)
         beta[i] = 0.0 ;
      for (i=0 ; i<ncases ; i++)         // Initial residuals are just the Y variable
         resid[i] = y[i] ;
      }

```

先前初始化代码最值得注意的方面是，如果我们正在进行热启动，并且我们没有使用快速协方差更新方法，那么我们必须重新计算残差。回想一下，方程 3-7 和 3-9 的简单更新方法需要残差。当然，如果我们从零开始所有的β权重，那么所有的预测也是零，残差只是目标。

随着迭代的进展，我们将计算解释的目标方差的分数，以启迪用户。为此，我们需要目标的均方差，如果用户选择了按重要性对案例进行加权，则需要对均方差进行适当加权。下面的代码计算这个数量:

```cpp
   if (w != NULL) {                // We need weighted squares to evaluate explained variance
      YmeanSquare = 0.0 ;
      for (i=0 ; i<ncases ; i++)
          YmeanSquare += w[i] * y[i] * y[i] ;
      }
   else
      YmeanSquare = 1.0 ;   // The target has been normalized to unit variance

```

我们现在开始主要的外部循环，迭代直到获得收敛。迭代限制`maxits`应该设置得非常大(几千或更多)以便它不会导致过早退出；只是“挂保险”。我们重置标志，该标志将指示活动集是否改变，并且我们将使用`max_change`来跟踪收敛测试的最大 beta 变化。

```cpp
   for (iter=0 ; iter<maxits ; iter++) {

      active_set_changed = 0 ;       // Did any betas go to/from 0.0?
      max_change = 0.0 ;                // For fast convergence test

```

对所有预测值进行一次遍历的循环现在开始。如果我们只处理活动集(非零 beta ),并且这个 beta 为零，跳过它。加权情况下的方程 3-9 和未加权情况下的方程 3-7 将需要分母中的`update_factor`，因此现在计算它。回想一下`XSSvec[]`是通过等式 3-13 计算出来的。

```cpp
      for (ivar=0 ; ivar<nvars ; ivar++) {  // Descend on this beta

         if (do_active_only  &&  beta[ivar] == 0.0)
            continue ;

         // Denominator in update
         if (w != NULL)       // Weighted?
            Xss = XSSvec[ivar] ;
         else
            Xss = 1 ;         // X was standardized
         update_factor = Xss + lambda * (1.0 - alpha) ;

```

我们计算软阈值函数的自变量。有三种可能。要么我们使用快速协方差更新方法，要么我们使用具有不同情况加权的朴素方法，要么我们使用具有相等加权的朴素方法。我们不必在这里将协方差更新方法分为有权重和无权重，因为在计算`Xss`、`Xinner`和`Yinner`时已经考虑了任何权重，如第 42 页所示。

```cpp
         if (covar_updates) {   // Any sensible user will specify this unless ncases < nvars
            sum = 0.0 ;
            for (kvar=0 ; kvar<nvars ; kvar++)
               sum += Xinner[ivar*nvars+kvar] * beta[kvar] ;
            residual_sum = Yinner[ivar] - sum ;
            argument = residual_sum + Xss * beta[ivar] ;   // Equation 3-10
            }

         else if (w != NULL) {         // Use slow naive formula (okay if ncases < nvars)
            argument = 0.0 ;
            xptr = x + ivar ;     // Point to column of this variable
            for (icase=0 ; icase<ncases ; icase++)   // Equation 3-8
               argument += w[icase] *
                                    xptr[icase*nvars] * (resid[icase] + beta[ivar] * xptr[icase*nvars])  ;
            }

         else {                          // Use slow naive formula (okay if ncases < nvars)
            residual_sum = 0.0 ;
            xptr = x + ivar ;        // Point to column of this variable
            for (icase=0 ; icase<ncases ; icase++)
               residual_sum += xptr[icase*nvars] * resid[icase] ;  // X_ij * RESID_i
            residual_sum /= ncases ;
            argument = residual_sum + beta[ivar] ;   // Equation 3-5
            }

```

我们刚刚计算了软阈值函数的自变量，方程 3-6 。应用该函数，并使用公式 3-7 或公式 3-9 计算该 beta 的新值。不久前，我们计算出`update_factor`是这些方程中的分母。

```cpp
         if (argument > 0.0  &&  S_threshold < argument)
            new_beta = (argument - S_threshold) / update_factor ;
         else if (argument < 0.0  &&  S_threshold < -argument)
            new_beta = (argument + S_threshold) / update_factor ;
         else
            new_beta = 0.0 ;

```

修正量是新的 beta 值和旧值之间的差值。记录这一过程中的最大变化，因为我们可能会用它来进行收敛测试。如果我们使用缓慢的朴素更新方法，我们也将使用这种校正来快速重新计算残差，这是朴素方法所需要的。

```cpp
         correction = new_beta - beta[ivar] ;
         if (fabs(correction) > max_change)
            max_change = fabs(correction) ;  // Used for fast convergence test

         if (correction != 0.0) {                       // Did this beta change?
            if (! covar_updates) {                    // Must we update the residual vector?
               xptr = x + ivar ;                           // Point to column of this variable
               for (icase=0 ; icase<ncases ; icase++)     // Update residual per this new beta
                  resid[icase] -= correction * xptr[icase*nvars] ;
               }
            if ((beta[ivar]==0.0  &&  new_beta!=0.0)  ||  (beta[ivar]!=0.0  &&  new_beta==0.0))
               active_set_changed = 1 ;
            beta[ivar] = new_beta ;
            }
         } // For all variables; a complete pass

```

根据`do_active_only`的说法，我们已经完成了一次测试，要么是所有的测试，要么只是活动集。我们现在做收敛测试，无论是快速，简单的版本或慢得多的版本。快速测试仅基于β的最大(所有预测值)变化。但是慢速测试更复杂。

如果我们使用快速协方差更新方法，我们不需要 beta 更新的残差，所以我们不需要(巨大的！)是时候计算它们了。但是我们需要残差来进行缓慢收敛测试，所以如果到目前为止我们还没有计算它们，我们必须计算它们。使用残差计算(可能加权的)均方误差。

```cpp
      if (fast_test) {             // Quick and simple test
         if (max_change < eps)
            converged = 1 ;
         else
            converged = 0 ;
         }

      else {   // Slow test (change in explained variance) which requires residual
         if (covar_updates) {  // We have until now avoided computing residuals
            for (icase=0 ; icase<ncases ; icase++) {
               xptr = x + icase * nvars ;
               sum = 0.0 ;
               for (ivar=0 ; ivar<nvars ; ivar++)
                  sum += beta[ivar] * xptr[ivar] ; // Cumulate predicted value
               resid[icase] = y[icase] - sum ;    // Residual = true - predicted
               }
            }

         sum = 0.0 ;         // Will cumulate squared error for convergence test
         if (w != NULL) {  // Are the errors of each case weighted differently?
            for (icase=0 ; icase<ncases ; icase++)
               sum += w[icase] * resid[icase] * resid[icase] ;
            crit = sum ;
            }
         else {
            for (i=0 ; i<ncases ; i++)
               sum += resid[i] * resid[i] ;
            crit = sum / ncases ;              // MSE component of optimization criterion
            }

```

模型的基本质量度量是模型解释的目标方差的分数。这是通过从目标的均方(方差)中减去刚刚计算的均方误差来计算的，以获得所解释的方差的量。将其除以目标均方差，得到模型所解释的目标方差的分数。这是严格用于可选的用户启发；它在优化算法中不起作用。

使用第 39 页的等式 3-3 计算正则化罚分，然后将该罚分与均方误差相加，得到我们最小化的标准，如第 38 页的等式 3-2 所示。

这个“慢”收敛标准是基于优化标准中从一次迭代到下一次迭代的变化。如果变化很小(其中“小”是由用户指定的`eps`定义的)，那么我们被认为已经收敛。

```cpp
         explained_variance = (YmeanSquare - crit) / YmeanSquare ;

         penalty = 0.0 ;
         for (i=0 ; i<nvars ; i++)
            penalty += 0.5 * (1.0 - alpha) * beta[i] * beta[i]  +  alpha * fabs (beta[i]) ;
         penalty *= 2.0 * lambda ;   // Regularization component of optimization criterion

         crit += penalty ;                   // This is what we are minimizing

         if (prior_crit - crit < eps)
            converged = 1 ;
         else
            converged = 0 ;

         prior_crit = crit ;
         }

```

现在，我们可以使用上一节中描述的控制逻辑完成外循环，在仅活动集和完整预测器通道之间交替。

```cpp
      if (do_active_only) {             // Are we iterating on the active set only?
         if (converged)                    // If we converged
            do_active_only = 0 ;       // We now do a complete pass
         }

      else {                                    // We just did a complete pass (all variables)
         if (converged  &&  ! active_set_changed)
            break ;
         do_active_only = 1 ;          // We now do an active-only pass
         }

      } // Outer loop iterations

```

我们基本上完成了。为了启发用户，我们计算并保存由模型解释的目标方差的分数。如果我们做了快速收敛测试和协方差更新，我们必须计算残差来得到解释的方差。这两个选项不需要常规的残差计算，所以我们目前没有残差。

```cpp
   if (fast_test  &&  covar_updates) {  // Residuals have not been maintained?
      for (icase=0 ; icase<ncases ; icase++) {
         xptr = x + icase * nvars ;
         sum = 0.0 ;
         for (ivar=0 ; ivar<nvars ; ivar++)
            sum += beta[ivar] * xptr[ivar] ;
         resid[icase] = y[icase] - sum ;
         }
      }

   sum = 0.0 ;
   if (w != NULL) {   // Error term of each case weighted differentially?
      for (i=0 ; i<ncases ; i++)
         sum += w[i] * resid[i] * resid[i] ;
      crit = sum ;
      }
   else {
      for (i=0 ; i<ncases ; i++)
         sum += resid[i] * resid[i] ;
      crit = sum / ncases ;                 // MSE component of optimization criterion
      }

   explained = (YmeanSquare - crit) / YmeanSquare ;

```

### 沿λ路径下行

如同通常具有超参数的模型的情况一样，为正则化强度λ(λ)选择有效值可能并不简单。在下一节中，我们将探索一种自动选择好值的好方法。在本节中，我们将介绍一个工具，该工具将由自动化例程调用，并且还可以用于帮助手动选择一个好的 lambda。

考虑一下，如果 lambda 很大，那么任何非零 beta 的惩罚都将很大，以至于所有 beta 权重都将被强制为零。(如果α正好为零，情况可能不是这样，所以从现在开始我们将假设*α*为 0。)这个模型显然是零解释方差。相反，如果λ = 0，那么我们有普通的线性回归，它具有最小可能的均方误差或最大可能的解释方差。因此，我们可以从一个较大的λ开始，训练模型，稍微降低λ，然后再次训练，以此类推，直到λ很小，几乎为零。我们通常会看到非零贝塔的数量稳步增加，以及解释方差。即使对于相同数量的非零贝塔，解释的方差也会随着λ的减小而增加。如果我们打印一张图表，显示非零贝塔值的数量和解释的方差作为λ的函数，我们也许能够对λ作出明智的选择。

这种方法有一个有趣的额外好处，即使我们事先知道我们想要使用的λ。这种方法增加了训练算法已经相当好的稳定性，而在速度方面没有太大的代价。事实上，我们可以这样训练*更快*。我们所做的是从一个大的 lambda 开始，这个 lambda 只给我们一个或很少几个有效的预测器。那种简单的模型会训练得很快。然后，当我们稍微降低 lambda 时，我们不是从头开始，而是热启动，从现有的 betas 开始迭代。所以，每次我们用稍小的λ重新开始训练，我们都是从已经非常接近正确的 betas 开始。因此，收敛将很快获得。

很容易为下降找到一个好的起始λ，最小的λ使得所有的贝塔为零。整个过程从所有 betas 为零开始。查看方程 3-7 ，以及自变量和软阈值算子的两个先前方程。对于差分加权的情况，在下一节中查看它们的类似物。回想一下，当所有贝塔系数都为零时，残差等于目标值， *y* 。根据软阈值函数的定义，很明显，如果未加权情况下的等式 3-16 或差分加权情况下的等式 3-17 为真，则 β 将保持为零。

![$$ \mathrm{AbsoluteValue}\kern0.5em \left[\frac{1}{N}\sum \limits_{i=1}^N\ {x}_{ij}\kern0.125em {y}_i\right]&lt;\lambda \alpha $$](img/474239_1_En_3_Chapter_TeX_Equ16.png)

(3-16)

![$$ \mathrm{AbsoluteValue}\kern0.5em \left[\sum \limits_{i=1}^N\ {w}_i\kern0.125em {x}_{ij}\kern0.125em {y}_i\right]&lt;\lambda \alpha $$](img/474239_1_En_3_Chapter_TeX_Equ17.png)

(3-17)

将这些方程的两边除以α得到任何预测因子的阈值λ，如果我们找到所有预测因子中的最大λ，我们就有了起始λ。下面是执行此操作的代码:

```cpp
double CoordinateDescent::get_lambda_thresh ( double alpha )
{
   int ivar, icase ;
   double thresh, sum, *xptr ;

   thresh = 0.0 ;
   for (ivar=0 ; ivar<nvars ; ivar++) {
      xptr = x + ivar ;
      sum = 0.0 ;
      if (w != NULL) {
         for (icase=0 ; icase<ncases ; icase++)           // Left side of Equation 3-17
            sum += w[icase] * xptr[icase*nvars] * y[icase] ;
         }
      else {
         for (icase=0 ; icase<ncases ; icase++)           // Left side of Equation 3-16
            sum += xptr[icase*nvars] * y[icase] ;
         sum /= ncases ;
         }
      sum = fabs(sum) ;
      if (sum > thresh)           // We must cover all predictors
         thresh = sum ;
      }

   return thresh / (alpha + 1.e-60) ;   // Solve for lambda; protect from division by zero
}

```

在 lambda 上下降很简单。需要注意的一点是，我们保存了每个试用 lambda 的 beta 权重，因为我们以后可能需要访问它们。此外，如果调用者设置了`print_steps`标志，这个例程将打开一个文本文件并附加结果，以便于用户检查。

我们使用`get_lambda_thresh()`找到最小的λ，确保所有的贝塔值保持为零，并稍微减小它以得到我们的起始λ。我们任意地将最小λ设置为该量的 0.001 倍。在构造函数调用中指定了试验次数。代码如下:

```cpp
void CoordinateDescent::lambda_train (
   double alpha ,                   // User-specified alpha, (0,1) (Greater than 0)
   int maxits ,                         // Maximum iterations, for safety only
   double eps ,                       // Convergence criterion, typically 1.e-5 or so
   int fast_test ,                      // Convergence via max beta change vs explained variance?
   double max_lambda ,        // Starting lambda, or negative for automatic computation
   int print_steps                    // Print lambda/explained table?
   )
{
   int ivar, ilambda, n_active ;
   double lambda, min_lambda, lambda_factor ;
   FILE *fp_results ;

   if (print_steps) {
      fopen_s ( &fp_results , "CDtest.LOG" , "at" ) ;
      fprintf ( fp_results , "\n\nDescending lambda training..." ) ;
      fclose ( fp_results ) ;
      }

   if (n_lambda <= 1)        // Nonsensical parameter from caller
      ireturn ;

/*
   Compute the minimum lambda for which all beta weights remain at zero
   This (slightly decreased) will be the lambda from which we start our descent.
*/

   if (max_lambda <= 0.0)
      max_lambda = 0.999 * get_lambda_thresh ( alpha ) ;
   min_lambda = 0.001 * max_lambda ;
   lambda_factor = exp ( log ( min_lambda / max_lambda ) / (n_lambda-1) ) ;

/*
   Repeatedly train with decreasing lambdas
*/

   if (print_steps) {
      fopen_s ( &fp_results , "CDtest.LOG" , "at" ) ;
      fprintf ( fp_results , "\nLambda  n_active  Explained" ) ;
      }

   lambda = max_lambda ;
   for (ilambda=0 ; ilambda<n_lambda ; ilambda++) {

      lambdas[ilambda] = lambda ;   // Save in case we want to use later
      core_train ( alpha , lambda , maxits , eps , fast_test , ilambda ) ;
      for (ivar=0 ; ivar<nvars ; ivar++)         // Save these in case we want them later
         lambda_beta[ilambda*nvars+ivar] = beta[ivar] ;

      if (print_steps) {
         n_active = 0 ;      // Count active predictors for user’s edification
         for (ivar=0 ; ivar<nvars ; ivar++) {
            if (fabs(beta[ivar]) > 0.0)
              ++n_active ;
            }
         fprintf ( fp_results , "\n%8.4lf %4d %12.4lf", lambda, n_active, explained ) ;
         }

      lambda *= lambda_factor ;
      }

   if (print_steps) 

      fclose ( fp_results ) ;
}

```

### 通过交叉验证优化 Lambda

如果不是最流行的，也是最流行的优化模型超参数的方法之一是交叉验证，所以这就是我们在这里要做的。原理很简单。对于每个折叠，我们调用`lambda_train()`来测试一组递减的λ，保存每个试验λ的β系数。然后，我们计算每个试验λ的样本外解释方差，并累积该量。当所有折叠完成后，我们检查合并的 OOS 性能，并选择哪个λ给出最佳 OOS 性能。不过，有一些事情需要注意，所以我们将把这段代码分成几个单独的部分，分别进行解释。下面是调用参数列表:

```cpp
double cv_train (
   int n ,                                  // Number of cases in full database
   int nvars ,                           // Number of variables (columns in database)
   int nfolds ,                          // Number of folds
   double *xx ,                        // Full database (n rows, nvars columns)
   double *yy ,                        // Predicted variable vector, n long
   double *ww ,                       // Optional weights, n long, or NULL if no weighting
   double *lambdas ,              // Returns lambdas tested by lambda_train()
   double *lambda_OOS ,      // Returns OOS explained for each of above lambdas
   int covar_updates ,            // Does user want (usually faster) covariance update method?
   int n_lambda ,                    // This many lambdas tested by lambda_train() (at least 2)
   double alpha ,                    // User-specified alpha, (0,1) (greater than 0)
   int maxits ,                         // Maximum iterations, for safety only
   double eps ,                       // Convergence criterion, typically 1.e-5 or so
   int fast_test                        // Convergence via max beta change vs explained variance?
   )

```

注意，这不是`CoordinateDescent`类的成员；这是一个独立的程序。大多数参数都是不言自明的，以前也见过很多次。最后四个参数和`covar_updates`只是传递给核心训练例程。我们必须提供两个向量`n_lambdas` long: `lambdas`将返回测试的λ值，`lambda_OOS`将返回对应于每个测试的λ的 OOS 解释的方差分数。我们应该指定尽可能大的`n_lambdas`来进行彻底的测试；50 不是不合理的。大量的 lambda 不会明显降低训练速度，因为使用了热启动，这意味着每次 lambda 降低时，beta 优化都在先前的最优值处开始。这非常快。最后，为了获得最佳精度，折叠次数也应该尽可能多；五个是最低限度，十个是合理的，如果计算机时间允许，更多更好。

我们从一些初始化开始。自然地，我们希望对每个折叠使用相同的降序 lambdas 集合，因此我们使用整个数据集来寻找阈值。如果案例被加权，我们复制归一化的权重用于 OOS 评分。第一次培训将从第一个案例开始，我们还没有做过任何 OOS 案例。我们将累积在`lambda_OOS`中解释的方差的分数，因此对于每个试验λ将这个向量初始化为零。我们将累积`YsumSquares`中的(可能加权的)目标平方和。

```cpp
   cd = new CoordinateDescent ( nvars , n , (ww != NULL) , covar_updates , n_lambda ) ;
   cd->get_data ( 0 , n , xx , yy , ww ) ;                       // Fetch the training set for this fold
   max_lambda = cd->get_lambda_thresh ( alpha ) ;
   if (ww != NULL) {
      for (icase=0 ; icase<n ; icase++)
         work[icase] = cd->w[icase] ;
      }
   delete cd ;

   i_IS = 0 ;          // Training data starts at this index in complete database
   n_done = 0 ;    // Number of cases treated as OOS so far

   for (ilambda=0 ; ilambda<n_lambda ; ilambda++)
      lambda_OOS[ilambda] = 0.0 ;  // Will cumulate across folds here

   YsumSquares = 0.0 ;     // Will cumulate to compute explained fraction

```

折叠循环从这里开始。OOS 案例的数量是剩余要做的数量除以剩余折叠的数量。其余情况是样本内的，OOS 集从 IS 集之后开始。

```cpp
   for (ifold=0 ; ifold<nfolds ; ifold++) {

      n_OOS = (n - n_done) / (nfolds - ifold) ;   // Number of cases in OOS  (test set)
      n_IS = n - n_OOS ;                                   // Number IS (training set)
      i_OOS = (i_IS + n_IS) % n ;                     // OOS starts at this index

```

我们现在用这个样本集训练，在 lambda 上下降。这个集合从索引`i_IS`开始，如果到达数据集的结尾，它将循环回到开始。

```cpp
      cd = new CoordinateDescent ( nvars , n_IS , (ww != NULL) , covar_updates ,
                                                        n_lam bda ) ;
      cd->get_data ( i_IS , n , xx , yy , ww ) ;                   // Fetch the training set for this fold
      cd->lambda_train ( alpha , maxits , eps , fast_test , max_lambda , 0 ) ;

```

训练已经完成，所以我们在 OOS 集上评估性能。下面是代码；下一页是逐步解释:

```cpp
      for (ilambda=0 ; ilambda<n_lambda ; ilambda++) {
         lambdas[ilambda] = cd->lambdas[ilambda] ;  // This will be the same for all folds
         coefs = cd->lambda_beta + ilambda * nvars ;
         sum = 0.0 ;
         for (icase=0 ; icase<n_OOS ; icase++) {
            k = (icase + i_OOS) % n ;
            pred = 0.0 ;
            for (ivar=0 ; ivar<nvars ; ivar++)
               pred += coefs[ivar] * (xx[k*nvars+ivar] - cd->Xmeans[ivar]) / cd->Xscales[ivar] ;
            Ynormalized = (yy[k] - cd->Ymean) / cd->Yscale ;
            diff = Ynormalized - pred ;
            if (ww != NULL) {
               if (ilambda == 0)
                  YsumSquares += work[k] * Ynormalized * Ynormalized ;
               sum += work[k] * diff * diff ;
               }
            else {
               if (ilambda == 0)
                  YsumSquares += Ynormalized * Ynormalized ;
               sum += diff * diff ;
               }
            }
         lambda_OOS[ilambda] += sum ;      // Cumulate for this fold
         }  // For ilambda

      delete cd ;
      n_done += n_OOS ;                           // Cumulate OOS cases just processed
      i_IS = (i_IS + n_OOS) % n ;               // Next IS starts at this index

      }  // For ifold

```

上一页的代码处理单个折叠的 OOS 集。随着有效的λ下降算法的进展，训练例程保存每个试验λ的β权重。因此，我们遍历 lambda，将每个 lambda 的 betas 放入`coefs`。我们将遍历所有 OOS 案例，累计`sum`中的误差平方和。

我们循环遍历数据集，当到达末尾时循环回到开始，因此`k`是将要测试的 OOS 案例的索引。OOS 情况(目标和所有预测值)必须以与训练数据相同的方式进行归一化，使用相同的平均值和标准差。

这种情况下的误差`diff`，是真实值减去预测值。我们累积平方误差，如果使用了不同的权重，则乘以用户指定的案例权重。我们同时累积归一化目标的平方和。这必须只做一次，因为它当然对所有试验 lambdas 都是一样的。当 case 循环完成时，我们将误差总和加到被测试的 lambda 的总和上。这个向量将累积所有折叠的总和。lambda 循环完成后，我们删除这个文件夹的`CoordinateDescent`对象，并前进到下一个文件夹。

剩下要做的就是计算每个 lambda 的 OOS 解释方差分数，并将表现最好的 lambda 返回给调用者。目标平方和减去误差平方和得到解释的平方和。将其除以目标 SS，得到解释方差的分数。

```cpp
   best = -1.e60 ;
   for (ilambda=0 ; ilambda<n_lambda ; ilambda++) {
      lambda_OOS[ilambda] = (YsumSquares - lambda_OOS[ilambda]) / YsumSquares ;
      if (lambda_OOS[ilambda] > best) {
         best = lambda_OOS[ilambda] ;
         ibest = ilambda ;
         }
      }

   return lambdas[ibest] ;
}

```

### CD_MA 程序

文件 CD_MA。CPP 包含一个程序，该程序读取市场价格文件，根据移动平均线振荡器计算大量指标，并使用`CoordinateDescent`正则化线性模型来找到指标的最佳子集，以预测第二天的(对数)价格变化。历史文件末尾的一年的市场数据将作为测试集使用。

使用以下命令调用该程序:

`CD_MA Lookback_inc N_long N_short Alpha Filename`

让我们来分解这个命令:

*   `Lookback_inc`:长期回看将从这个数量的棒线(包括当前棒线)开始回看。后续的长期回顾将以此数量递增。例如，如果指定为 3，则长期回看将为 3、6、9，....

*   这么多的长期回顾将会被采用。最大长期回顾将是`Lookback_inc * N_long`。

*   这么多的短期回顾将会被采用。它们是当前的长期回顾时间 *i* 然后除以`N_short+1`，对于从 1 到`N_short`的 *i* ，被截断成整数。注意，当当前长期回顾小于`N_short+1`时，将会有多个相同的短期回顾值，从而产生完全相关的预测值。指标总数为`N_long` * `N_short`。

*   `Alpha`:控制正则化类型所需的 alpha。如果指定小于或等于零，lambda 将被设置为零，产生普通线性回归(无正则化)。它决不能大于或等于 1。

*   `Filename`:格式为`YYYYMMDD Open High Low Close`的市场历史文件。

将打印两个表格。第一部分显示了选择最佳λ所涉及的计算。此表中的左栏列出了试用的 lambdas。右栏显示解释方差的相应样本外分数。

第二个表列出了β系数。每一行对应一个长期回顾，回顾打印在每一行的开头。每根柱对应一个短期回看。这些回看不会被打印，因为它们随每行而变化。它们可以用前页的公式很容易地计算出来。精确为零的系数(通常但不总是因为训练算法将它们从模型中移除)用虚线表示。

图 3-1 显示了当λ= 0，无正则化时，为 OEX 产生的β系数表。这实际上等同于普通的线性回归。图 3-2 显示 alpha=0.1 时的结果，图 3-3 针对 alpha=0.9。讨论如下。

![img/474239_1_En_3_Fig3_HTML.png](img/474239_1_En_3_Fig3_HTML.png)

图 3-3

阿尔法=0.9

![img/474239_1_En_3_Fig2_HTML.png](img/474239_1_En_3_Fig2_HTML.png)

图 3-2

阿尔法=0.1

![img/474239_1_En_3_Fig1_HTML.png](img/474239_1_En_3_Fig1_HTML.png)

图 3-1

λ= 0(无正则化)

这次运行使用 OEX S&P 100 指数作为它的市场历史。回望增量为 2，有 30 次长期回望和 10 次短期回望。

*   回想一下本节第一页的讨论，对于小于短期回顾数加 1 的长期回顾，一些短期回顾必须重复，这意味着一些指标是其他指标的精确副本。

*   这种重复使得普通的线性回归变得不可能，因为一些权重是未定义的。将需要诸如奇异值分解的特殊技术。这里 lambda=0 的算法处理得很好，甚至有效地消除了一些重复。但是绝大多数指标都参与了这个模型。

*   因为当λ= 0 时，没有正则化，这是完全最小二乘拟合。这意味着解释方差的样本内部分应该是最大可能值，事实上我们看到了这种情况，解释了 1.63%的目标方差。

*   由于大量的指标参与(没有正规化)，我们预计会看到 OOS 表现不佳。是的，这是三次测试中得分最差的一次。

*   当我们应用 alpha=0.1 的正则化(近似岭回归)时，样本内解释方差下降，但 OOS 性能飙升至最佳。

*   在 alpha=0.1 的情况下，我们看到重复的指示符接收到相同的 beta 系数，如预期的那样。

*   当 alpha=0.9(接近套索)时，模型会最小化保留的指标数量，以尝试使模型尽可能简单，即使以牺牲性能为代价。我们看到这种情况发生，甚至选择的指标也发生了变化。OOS 业绩暴跌，意味着该模型被迫放弃一些有用的指标。

*   正则化的模型都是负系数，说明这个交易系统是均值回归系统，不是趋势跟随者！

## 使线性模型变得非线性

尽管线性模型往往比非线性模型更受青睐，但有时我们的两个或更多指标在与目标的关系中存在不可避免的非线性相互作用。要知道，一个指标仅仅与目标有一个非线性关系，就其本身而言，通常不是问题。我们可以通过某种方式改变指标，使其与目标之间的关系变得基本上是线性的。至少尝试一下总是件好事。当然，也可能发生这样的情况，我们只是怀疑一个单独的非线性关系，但我们无法证明它足以能够合理地转换指标。但是在绝大多数情况下，当指标在与目标的联合关系方面以非线性方式相互作用时，线性模型就会失效。在这种情况下，我们别无选择，只能放弃严格的线性模型。

但是并没有失去一切。线性模型的优势，尤其是正则化模型的优势(对其工作原理的简单理解、快速训练、较低的过拟合可能性)如此之大，以至于值得以适度非线性的方式转换指标及其相互作用，并将这些新值应用于正则化线性模型。我们几乎从来不想采用如此极端的措施，以至于交易决策的界限到处游走，为了抓住每一个错误的训练案例而扭曲。但是有一种简单的方法来应用适度的非线性变换，允许我们以温和的非线性方式使用正则化的线性模型。

自然，我们可以用一个或多个原始预测值的一个或多个非线性函数来补充模型的预测值。如果我们有选择某些特定函数的理论理由，我们当然应该这样做。但那种情况很少见。最常见和最有效的一般程序是使用低次多项式，我将很快讨论两个特殊的扭曲。总体思路是这样的:我们选择低学位，一般是二级，很少是三级。此外，选择一个子集的预测，我们希望允许非线性相互作用。这可能是所有的预测因素，尽管当我们包含更多的预测因素时，事情会变得更糟。然后在选定的程度上，用它们的每一种可能的组合来补充原始预测值。

例如，假设我们有三个预测值，我们希望考虑非线性。称他们为 *A、B* 和 *C* 。还假设我们想允许二级，最常见的选择。那么我们发给模型的预测器是 *A* 、 *B* 、 *C* 、 *A* <sup>2</sup> 、 *B* <sup>2</sup> 、 *C* <sup>2</sup> 、 *AB* 、 *AC* 、 *BC* 。如果我们决定向上移动到第三级，附加的预测因子是 *A* <sup>3</sup> 、 *B* <sup>3</sup> 、 *C* <sup>3</sup> 、*A*<sup>2</sup>*B*、*A*<sup>2</sup>*C*、*B 显而易见，增加非线性集合中预测因子的数量，或者增加多项式的次数，会导致新预测因子数量的爆炸性增长。*

当使用多项式展开时，有两件事应该做。这两者都不是数学上必需的，但如果我们要防止硬件浮点不准确性，以及提高大多数模型训练算法的速度和稳定性，这两者都很重要。首先，我们必须确保转换后的指标具有大约负一比一的自然范围。如果做到了这一点，所有的多项式变换值都具有相同的自然范围。如果我们的原始指标没有这个范围，至少近似地，我们应该从理论考虑或从大的代表性集合的检查中找到它们的真实自然范围，*最小*到*最大*。则 *X* 的量程调整值为 2 *(??)X–*Min*)/(*Max*–*Min*)–1。

我们应该采取的另一个行动只有在我们达到第三级(或者，但愿不会如此，更高级)时才需要。问题是，即使有范围调整， *X* 和 *X* <sup>3</sup> 可以有足够的相关性，稍微妨碍一些训练算法。它很少是严重的，并且将要描述的技术可能会被一些人认为是过度的，但是它是一个具有良好回报的廉价投资。不使用*X*3，而是使用 0.5 *(5*X*3–3*X*)。这仍然是一个范围为负一比一的三次多项式，它将允许与*X*3 相同的有效非线性，但它通常与 *X* 的相关性要小得多，因此将由许多训练算法更有效地处理。你不会有任何损失，而且可能会有很大收获。

超越三级几乎总是毫无意义的。如果你有那么多的非线性，就用非线性模型。但是如果出于某种原因你坚持的话，查查*勒让德多项式*并用它们来表示高次项。

## 差分进化:一种通用的非线性优化器

无论你的交易系统是基于非线性预测模型还是传统的算法(基于规则)系统，你都需要一个快速稳定的方法来优化你选择的性能标准。在大多数情况下，优化算法的选择涉及到一个重要的权衡。一个多变量函数通常有几个(也许很多！)局部 optima。最快的优化者是爬山者，迅速爬到最近的山顶，不管那个特定的山是不是最好的。更有可能在众多山顶中找到最佳山顶的优化者比简单的爬山者要慢得多。那么，该怎么办呢？

幸运的是，有一种算法是两个极端之间的一个很好的妥协。在众多山顶中，它找到最好的，或者至少接近最好的山顶的可能性相对较高，但它的速度也相当快。这种算法是一种特殊的遗传或进化优化，称为*差分进化*。我不会在这里提供任何参考，因为互联网上充满了例子和讨论。相反，我将把重点放在这个算法的一个高度调整的变体上，我已经在我自己的工作中使用了多年，并且我发现它是一个可靠的执行者。

像所有的进化算法一样，它从一群个体开始，每个个体都是交易系统的一个完全指定的参数集。然后，它遍历整个种群，以一种很有可能产生优于双亲的个体的方式组合种群中不同成员的品质。

不同于大多数植物和动物的繁殖，差异进化需要四个个体才能产生一个孩子。其中一个被称为*父代 1* ，是确定性选择的。另外三个*父母 2* 、*差异 1* 和*差异 2* 是随机选择的。两个差值决定了一个方向，并且 *Parent2* 在这个方向上被扰动。通过从 *Parent1* 中选择一些参数以及从受干扰的 *Parent2* 中选择其他参数来创建新子节点。如图 3-4 和图 3-5 所示。

![img/474239_1_En_3_Fig5_HTML.jpg](img/474239_1_En_3_Fig5_HTML.jpg)

图 3-5

差异子代

![img/474239_1_En_3_Fig4_HTML.jpg](img/474239_1_En_3_Fig4_HTML.jpg)

图 3-4

差异进化的一步

图 3-4 显示一阶和二阶微分相减，它们的差乘以一个常数，通常小于 1。这个缩小的差被加到第二个亲本上，和在随机交叉操作中与第一个亲本合并。将这个子代的表现与主要父代的表现进行比较，并为下一代保留优越的个体。

这在图 3-5 中用图形显示了两个变量。两个微分之间的差决定了一个方向，次级母体在这个方向上被扰动。在这个例子中，这个操作被称为*突变*，尽管这不是一个通用术语。然后水平变量取自第一亲本，垂直变量取自变异的第二亲本。

这个方案有一个重要的性质:它将扰动缩放到参数的自然尺度。假设功能函数在某个方向上有一个狭窄的脊，这是一种常见的情况。那么人口会被吸引到同样的布局。个体(完整的参数集)将在脊的方向上广泛分布，而在垂直方向上被压缩。其结果是，控制次级母体扰动程度的微分差将沿着脊变大，沿着脊变小，这正是我们想要的。

不幸的是，差分进化有一个大多数随机过程共有的弱点:它很快收敛到全局最优附近，但从来没有完全达到精确的最优。这是因为它本质上无法利用函数的本地知识。爬山法在收敛到局部最优方面做得很好，但是它们容易因为错过全局最优而失败。所以，我的方法是混合的，主要实现差异进化，但偶尔对单个个体执行爬山步骤。这极大地加速了收敛，同时对算法的全局影响可以忽略，因为该操作在任何时候都保持在单个个体的吸引域内。

此处显示了下一页的算法概述。

```cpp
for (ind=0 ; ind<popsize+overinit ; ind++) { // Generate the basis population
   Generate a random parameter vector
   value = performance of this random vector

   If this individual fails to meet a minimum requirement {
      --ind ;          // Skip it entirely
      continue ;
      }

   if (ind >= popsize) {  // If we finished population, now doing overinit
      Find the worst individual in population (popsize individuals)
      if (value > worst)
         Replace the worst with this new individual
      } // If doing overinit
   } // For all individuals (population and overinit)

for (generation=1 ; ; generation++) {

   for (ind=0 ; ind<popsize ; ind++) {  // Generate all children
      parent1 = individual 'ind'

      Generate three different random indices for parent2 and the two differentials:
         parent2, diff1, diff2

      for all variables j {   // This is the mutation and crossover step
         with small probability
            trial[j] = parent2[j] + constant * (diff1[j] - diff2[j]) ;
         else
            trial[j] = parent1[j] ;
         }
      value = performance of trial parameter set

      if (value > parent1's performance)
         replace parent1 with trial parameter set

      Optionally pick one variable in one individual (favoring the best so far)
      and find the optimal value of that variable

      } // Create all children in this generation
   } // For all generations

Return the best individual in the final population

```

第一步是生成一个初始群体，这是由这段伪代码中的第一个循环完成的。用户指定群体中的个体数量`popsize`。传统算法不包括过度初始化，测试`overinit`额外的个体。我发现，将`overinit`设置为大约`popsize`会以相对较小的额外成本产生一个具有更快收敛速度和更好全局代表性的显著更优的初始种群。

这个群体生成循环创建一个随机个体(完整的交易系统参数集)并计算其性能。如果这个人没有满足任何用户指定的要求，比如最低交易次数，他就会被拒绝，我们会再试一次。

当我们生成了`popsize`个个体并进入过度初始化时，对于每个新的候选人，我们在现有的群体中搜索表现最差的个体。如果新的候选人优于群体中最差的个体，则新的候选人取代最差的个体。这稳定地提高了群体的质量，也使我们更有可能在全局最优的吸引域中有一个或多个个体。

然后我们来看代码的进化部分。有两个嵌套循环。外部循环处理世代，在每一代中，我们将当前群体中的每个个体作为主要父代。次要亲本和两个差异个体是随机选择的，当然这四个个体必须是不同的。

为了提高效率，变异(通过缩小差异来干扰次级亲本)和交叉(用相应的变异变量随机替换初级亲本中的一些变量)在同一循环中完成。我们遍历所有变量来创建一个试验个体。对于每一个，我们掷骰子，通常以很小的概率将变量设置为变异值。否则，我们从主父节点复制变量。

我们计算这个试验个体的表现。如果它优于原始亲本，它将进入下一代群体。否则，主要的父代会延续到下一代。

最后，我们可选地执行传统算法中没有出现的步骤，但是我发现该步骤在加速收敛方面是有用的，同时在存在多个次优局部最优解的情况下对算法找到全局最优解的能力影响很小或者没有影响。我们在人群中挑选一个个体，对当前最好的个体有所偏爱，我们也挑选一个变量。我们使用爬山算法来找到这个变量的值，以优化这个个体的性能。这给了我们两个世界(随机优化与爬山)的最佳选择，因为它让算法准确地收敛到精确的最优值，比纯粹的随机算法快得多，同时它不干扰差分进化找到全局最优值的能力。这是因为当它完成时，它只发生在一个个体上，这使该个体保持在其局部最优的吸引域内，而不触及群体中可能具有其自己的吸引域的其他个体。因此，吸引域保持分离，使全球最佳者最终占据主导地位。

在所有代完成后，我们选择最终种群中最好的个体，并将其返回给用户。

为了清楚起见，刚刚显示的算法被简化了。我的实现要复杂得多，因为这些年来我已经用许多方法对它进行了改进，以调整它的性能，尤其是在优化交易系统的情况下。从下一页开始，我们将完成整个子程序，分别列出和注释每个部分。这个代码可以在 DIFF_EV.CPP 文件中找到。注意，这个文件还包含一些与差异进化无关但同时执行起来很有效的其他代码。我们将在这里忽略这段代码，在第 91 页详细讨论。

### DIFF_EV 差异进化的 CPP 程序

使用以下参数列表调用差分进化子例程:

```cpp
int diff_ev (
   double (*criter) ( double * , int ) , // Crit function maximized
   int nvars ,                                     // Number of variables (trading system parameters)
   int nints ,                                      // Number of first variables that are integers
   int popsize ,                                 // Population size
   int overinit ,                                  // Overinitialization for initial population
   int mintrades ,                             // Minimum number of trades for candidate system
   int max_evals ,                            // For safety, max number of failed initial performance evals
   int max_bad_gen ,                      // Max number of contiguous gens with no improvement
   double mutate_dev ,                   // Deviation for differential mutation
   double pcross ,                            // Probability of crossover
   double pclimb ,                            // Probability of taking a hill-climbing step, can be zero
   double *low_bounds ,                  // Lower bounds for parameters
   double *high_bounds ,                // And upper
   double *params ,                         // Returns nvars best parameters, plus criterion at end
   int print_progress                        // Print progress to screen?
   )

```

调用者提供的`criter()`函数计算交易系统的性能标准，该标准将被最大化。它采用交易系统可优化参数的向量。在我的实现中，还提供的整数是用户指定的最小交易数。读者应该会发现，在为生成的交易系统设置最低要求时，很容易添加其他变量。

参数可以是整数或实数；正如将要看到的，它们在内部被不同地处理。所有整数参数必须在参数数组中排在第一位，`nints`指定整数的个数。

用户可以将`overinit`设置为零，以使用传统版本的算法。然而，我发现将其设置为等于`popsize`附近的值是有利的。这有助于加速收敛并增加找到真正全局最大值的概率。但请注意，收益递减点很快就会达到。很快就会发生这样的情况，稳定改进的群体中最差的个体通常优于大多数过度初始化的个体，使得继续过度初始化是一种浪费。

用户在`mintrd`中指定所需交易的最小数量。从代码演示中可以看出，如果优化器很难找到满足这个要求的系统，那么指定的数量可能会自动减少。因此，用户应该检查通过最佳系统获得的交易数量，以确认它是令人满意的。如果程序员愿意，消除这种自动减少是很容易的，但我发现它很有用。

`max_evals`参数是一种安全措施。如果交易系统本质上很差，以至于大多数试验参数都产生了被拒绝的系统，那么产生初始群体就要花费大量的时间。为了防止这种情况，请将`max_evals`设置为一个较大但合理的值。这不应该被认为是一个收敛测试；实际上，这个极限应该*永远不会*遇到。

收敛由`max_bad_gen`参数定义。如果这许多连续的*代在最佳个体中没有改进，则获得收敛，并且算法停止。这通常应该是相当大的，也许 50 甚至更多，因为事情可能会因为运气不好而变得糟糕，然后突然再次起飞。*

当一个突变的参数替换了主亲本中的相应参数时，就会发生一个*交叉*，这种情况发生的概率由`pcross`给出。这通常应该很小，可能最多为 0.1 到 0.5。

爬山步骤的概率由`pclimb`给出。这可以是零，以严格避免爬山，保持传统版本的差异进化。它可以被设置为一个很小的正值，比如 0.00001，在这种情况下，当前最好的个体(没有其他人)偶尔会爬山。这最大限度地提高了末期精确收敛。最后，可以将其设置为稍大但仍然较小的值，如 0.2。这样，除了调整最佳个体，它还会偶尔随机调整其他个体。将它设置为较大的值通常不是很有利，因为爬山是一种昂贵的操作，尤其是对于实参数，偶尔多做一次的回报通常不足以补偿增加的成本。此外，如果爬山太频繁，对真正的全局最大值的检测可能会有些受阻，尽管这通常不是问题。

调用者必须分别使用`low_bounds`和`high_bounds`向量来指定参数的下限和上限。

长度必须为`nvars` +1 的`params`向量返回最佳参数。这个数组中的最后一项是这个最优参数集的标准函数值。

如果`print_progress`输入非零，频繁的进度报告将被打印到控制台屏幕上。

只分配了三个工作数组:一个用于保存“当前”群体，一个用于保存正在创建的群体，一个短数组用于跟踪最佳个体。我们使用`failures`来计算初始群体中随机产生的个体被拒绝的次数，通常是因为交易系统的交易太少。我们很快就会看到，它将被用来降低最低交易要求。为了安全起见，`n_evals`统计我们评估随机生成的个体以创建初始群体的总次数。这样可以紧急逃生，避免挂电脑。第一个`popsize`个体填充`pop1`数组，过度初始化进入`pop2[0]`。

```cpp
   dim = nvars + 1 ;  // Each individual is nvars variables plus criterion
   pop1 = (double *) malloc ( dim * popsize * sizeof(double)) ;
   pop2 = (double *) malloc ( dim * popsize * sizeof(double)) ;
   best = (double *) malloc ( dim * sizeof(double)) ;

   failures = 0 ;       // Counts consecutive failures
   n_evals = 0 ;      // Counts evaluations for catastrophe escape

   for (ind=0 ; ind<popsize+overinit ; ind++) {
      if (ind < popsize)                         // If we are in pop1
         popptr = pop1 + ind * dim ;       // Point to the slot in pop1
      else                                             // Use first slot in pop2 for work
         popptr = pop2 ;                         // Point to first slot in pop2

```

我们现在生成一个随机个体，并将其放入`popptr`。第一个`nints`参数为整数，其余为实数。这两种类型都是通过在各自的指定范围内统一选择值来生成的。然而，整数和实数的处理略有不同。函数`unifrand()`生成一个 0-1 范围内的均匀随机数。

```cpp
      for (i=0 ; i<nvars ; i++) {       // For all variables (parameters)

         if (i < nints) {                     // Is this an integer?
            popptr[i] = low_bounds[i]+(int)(unifrand() * (high_bounds[i]-low_bounds[i] + 1.0));
            if (popptr[i] > high_bounds[i])  // Virtually impossible, but be safe
               popptr[i] = high_bounds[i] ;
            }

         else                                   // real
            popptr[i] = low_bounds[i] + (unifrand () * (high_bounds[i] - low_bounds[i])) ;
         } // For all parameters

```

评估此人的交易系统表现，参数设置在`popptr`中。将此性能保存在`popptr`的最后一个槽中，紧接在参数之后。回想一下，每个槽都是`nvars+1`长。在构建初始群体时，计算性能评估的数量，以便我们可以将其作为紧急出口，以避免陷入表面上(或实际上！)死循环。最后，初始化第一个被测试者的最佳、最差和平均表现。这个`memcpy()`将这个人的参数和表现复制到短数组中，在这里我们记录下有史以来最好的成绩，最终返回给用户。

```cpp
      value = criter ( popptr , mintrades ) ;
      popptr[nvars] = value ;          // Also save criterion after variables
      ++n_evals ;                           // Count evaluations for emergency escape

      if (ind == 0) {
         grand_best = worstf = avgf = value ;
         memcpy ( best , pop1 , dim * sizeof(double) ) ; // Best so far is first!
         }

```

下一个代码块处理被拒绝的个体。请注意，此代码使用零阈值来拒绝参数集，例如显示亏损或未能满足最小交易计数要求。如果您想要使用一个不同的性能标准，一个不适合这个阈值的标准，您应该修改这个代码，或者更好的是，转换您的性能标准。例如，如果您想要最大化利润因子，那么合适的阈值应该是 1 而不是 0，您可以将您的绩效定义为利润因子的对数。

在下面显示的拒绝处理代码中，我们首先检查我们是否有如此糟糕的交易系统，以至于生成初始群体所需的评估数量已经失控，在这种情况下，我们采取紧急退出。如果没有，我们计算这种失败的次数。如果达到了一个很大的数字(500 在这里是硬编码的；随意更改)，我们重置失败计数器并降低最低交易要求，因为根据我的经验，这是最常见的失败原因，除非`mintrades`被设置得非常小。在任何情况下，这个个体的失败导致它被跳过，而成功重置失败计数器。因此，需要一个*批次*的失败来触发最小交易计数的减少。在采取这种激烈的行动之前，情况必须非常糟糕。

```cpp
      if (value <= 0.0) {                 // If this individual is totally worthless
         if (n_evals > max_evals)  // Safety escape should ideally never happen
            goto FINISHED ;
         --ind ;                                 // Skip it entirely
         if (++failures >= 500) {      // This many in a row
            failures = 0 ;
            mintrades = mintrades * 9 / 10 ;
            if (mintrades < 1)
               mintrades = 1 ;
            }
         continue ;
         }
      else
         failures = 0 ;

```

我们保持最佳、最差和一般的表现。后两个是严格的进度报告，如果用户不会更新进度，最差和平均计算可以省略。

```cpp
      if (value > grand_best) {   // Best ever
         memcpy ( best , popptr , dim * sizeof(double) ) ;
         grand_best = value ;
         }

      if (value < worstf)
         worstf = value ;

      avgf += value ;

```

如果我们已经找到了`popsize`个个体，我们就进入了过度初始化。在现有人群中搜索最差的个体。如果这个新的过度初始化的个体优于最差的，用它替换最差的，这样就改善了基因库。回想一下，性能存储在参数之后，所以它在索引`[nvars]`处。同样，我们只对用户更新保持平均性能；它在优化算法中不起作用。

```cpp
      if (ind >= popsize) {               // If we finished pop1, now doing overinit
         avgf = 0.0 ;
         minptr = NULL ;                  // Not needed.  Shuts up 'use before define'
         for (i=0 ; i<popsize ; i++) {  // Search pop1 for the worst
            dtemp = (pop1+i*dim)[nvars] ;
            avgf += dtemp ;
            if ((i == 0)  ||  (dtemp < worstf)) {
               minptr = pop1 + i * dim ;
               worstf = dtemp ;
               }
            } // Searching pop1 for worst
         if (value > worstf) {            // If this is better than the worst, replace worst with it
            memcpy ( minptr , popptr , dim * sizeof(double) ) ;
            avgf += value - worstf ;  // Account for the substitution
            }
         } // If doing overinit

      } // For all individuals (population and overinit)

```

此时，我们已经完全生成了初始群体。找到最好的执行者，因为我们偶尔会在上面做一点爬山(除非用户禁止这样做，这通常是一个糟糕的举动)。然后将点设置为旧(源)代和新(目的)代，并将收敛计数器归零。我们将使用`n_tweaked`来控制爬山。

```cpp
   ibest = n_tweaked = 0 ;
   value = pop1[nvars] ;
   for (ind=1 ; ind<popsize ; ind++) {
      popptr = pop1 + ind * dim ;       // Point to the slot in pop1
      if (popptr[nvars] > value) {
         value = popptr[nvars] ;
         ibest = ind ;
         }
      }

   old_gen = pop1 ;              // This is the old, parent generation
   new_gen = pop2 ;            // The children will be produced here
   bad_generations = 0 ;      // Counts contiguous generations with no improvement of best

```

我们有嵌套循环，代是外部循环，代中的个体是内部循环。仅针对可选用户更新跟踪平均和最差情况。变量`improved`标记最佳个体是否在这一代中的任何一点上有所改进。这用于表示收敛。主父代`parent1`来自源群体，我们将创建的子代将进入目标群体。

```cpp
   for (generation=1 ; ; generation++) {

      worstf = 1.e60 ;
      avgf = 0.0 ;
      improved = 0 ;                                        // Will flag if we improved in this generation

      for (ind=0 ; ind<popsize ; ind++) {          // Generate all children for this generation

         parent1 = old_gen + ind * dim ;           // Pure (and tested) parent
         dest_ptr = new_gen + ind * dim ;        // Winner goes here for next gen

```

我们随机选择第二个父代和两个差异。这些必须不同于主要的亲本并且彼此不同。

```cpp
         do { i = (int) (unifrand() * popsize) ; }
            while ( i >= popsize || i == ind ) ;

         do { j = (int) (unifrand() * popsize) ; }
            while ( j >= popsize || j == ind || j == i ) ;

         do { k = (int) (unifrand() * popsize) ; }
            while ( k >= popsize || k == ind || k == i || k == j ) ;

         parent2 = old_gen + i * dim ;    // Parent to mutate
         diff1 = old_gen + j * dim ;         // First differential vector
         diff2 = old_gen + k * dim ;        // Second differential vector

```

下面的代码负责变异和交叉来创建一个新的子节点。我们将遍历每个参数，随机决定每个参数是否变异和交叉。如果我们到了最后一个参数，但还没有这样做，我们就这样做，以确保至少有一个变化。我们随机选择一个起始参数，这样当我们到达终点时，我们不会总是在同一个地方进行最后的动作。这种变异很容易将参数推到合法范围之外。根据需要修复此问题。`ensure_legal()`例程将在后面讨论。

```cpp
         do { j = (int) (unifrand() * nvars) ; }
            while ( j >= nvars ) ;  // Pick a starting parameter

         used_mutated_parameter = 0 ;         // We must act at least once; we haven’t yet

         for (i=nvars-1 ; i>=0 ; i--) {
            if ((i == 0 && ! used_mutated_parameter) || (unifrand() < pcross)) {
               dest_ptr[j] = parent2[j] + mutate_dev * (diff1[j] - diff2[j]) ;
               used_mutated_parameter = 1 ;
               }   // We mutated this variable
            else   // We did not mutate this variable, so copy old value
               dest_ptr[j] = parent1[j] ;
            j = (j + 1) % nvars ;   // Rotate through all variables
            }

         ensure_legal ( nvars , nints , low_bounds , high_bounds , dest_ptr ) ;

```

评估这个新创建的孩子的表现。如果优于初级亲本，放入目的群体。否则，将主要父代复制到目标群体中。记录有史以来最好的个人，它最终会返回给呼叫者。通过`improved`表明我们这一代有所进步，所以我们还不准备放弃。变量`n_tweaked`将很快与爬山结合使用。

```cpp
         value = criter ( dest_ptr , mintrades ) ;

         if (value > parent1[nvars]) {          // If the child is better than parent1
            dest_ptr[nvars] = value ;            // Get the child's value (The vars are already there)
            if (value > grand_best) {            // And update best so far
               grand_best = value ;
               memcpy ( best , dest_ptr , dim * sizeof(double) ) ;
               ibest = ind ;
               n_tweaked = 0 ;
               improved = 1 ;                         // Flag that the best improved in this generation
               }
            }

         else {                                             // Else copy parent1 and its value
            memcpy ( dest_ptr , parent1 , dim * sizeof(double) ) ;
            value = parent1[nvars] ;
            }

```

我们现在开始可选的(但非常有用的)爬山步骤。下面的代码是决定是否爬山和爬什么的逻辑。我们将在下一页讨论它。

```cpp
         if (pclimb > 0.0  &&
                      ((ind == ibest  &&  n_tweaked < nvars)  ||  (unifrand() < pclimb))) {
            if (ind == ibest) {                             // Once each generation tweak the best
               ++n_tweaked ;                             // But quit if done all vars
               k = generation % nvars ;              // Cycle through all vars
               }
            else {                                               // Randomly choose an individual
               k = (int) (unifrand() * nvars) ;        // Which var to optimize
               if (k >= nvars)                               // Safety only
                  k = nvars - 1 ;
               }

```

如果用户指定`pclimb` =0，那么爬山(这里称为*调整*)将永远不会完成。假设我们可以做到这一点，检查两个条件，其中任何一个都将允许对这个个体进行单次攀爬操作，这个个体可能是新创建的子体，也可能是主要父体的副本。如果个体是目前为止最好的，并且它的所有变量都没有被调整，我们就调整它。回想一下，每次 grand best 改变时,`n_tweaked`被重置为零。如果这是最好的，我们计算这种调整，并根据代选择变量。最优秀的个体在连续多代中保持不变是很常见的，这种参数选择会导致调整在参数之间轮换，从而避免重复。

如果第一次测试失败(要么这不是最好的个体，要么它的所有参数都已经被调整)，那么我们掷骰子，随机决定是否调整这个个体中随机选择的参数。

整数和实数参数的调整方式不同，前者更简单、更快。下面是整数代码的一半:

```cpp
            if (k < nints) {             // Is this an integer?
               ivar = ibase = (int) dest_ptr[k] ;
               ilow = (int) low_bounds[k] ;
               ihigh = (int) high_bounds [k] ;
               success = 0 ;
               while (++ivar <= ihigh) {
                  dest_ptr[k] = ivar ;
                  test_val = criter ( dest_ptr , mintrades ) ;
                  if (test_val > value) {
                     value = test_val ;
                     ibase = ivar ;
                     success = 1 ;
                     }
                  else {
                     dest_ptr[k] = ibase ;
                     break ;
                     }
                  }

```

我们在`ibase`中保存了这个参数的当前值，因此如果没有发现改进，我们可以恢复它。我们将在当前值附近改变`ivar`以寻求改进。对其整个合法范围进行全面的全球搜索通常是浪费时间。如果我们发现任何改进，变量`success`就会标记。我们向上移动参数，直到它达到上限或者性能没有提高。(为了保持快速搜索，这里忽略了平坦性能之后进行改进的可能性。)只要我们在改进，我们就不断更新`ibase`和改进后的值。当性能没有提高时，这可能发生在第一次测试中，我们将参数设置为`ibase`，并停止前进。

如果增加参数没有成功，我们会尝试减少参数。该算法本质上与向上搜索算法相同，因此在这里讨论它没有意义。

```cpp
               if (! success) {
                  ivar = ibase ;
                  while (--ivar >= ilow) {
                     dest_ptr[k] = ivar ;
                     test_val = criter ( dest_ptr , mintrades ) ;
                     if (test_val > value) {
                        value = test_val ;
                        ibase = ivar ;
                        success = 1 ;
                        }
                     else {
                        dest_ptr[k] = ibase ;
                        break ;
                        }
                     } // While searching downward
                  } // If the upward search did not succeed
               } // If k < nints (this parameter is an integer)

```

处理实参数的代码稍微复杂一点。如下一页所示，我们从将性能计算所需的信息复制到静态变量开始，所有这些都以`local_`开始。该技术允许参数优化例程是通用的，调用仅引用被优化的参数的标准函数。

```cpp
            else {                                      // This is a real parameter
               local_criter = criter ;
               local_ivar = k ;                    // Pass it to criterion routine
               local_base = dest_ptr[k] ;   // Preserve orig var
               local_x = dest_ptr ;
               local_nvars = nvars ;
               local_nints = nints ;
               local_low_bounds = low_bounds ;
               local_high_bounds = high_bounds ;
               old_value = value ;

```

优化分两步完成。首先，我们调用一个粗略的全局搜索例程`glob_max()`(GLOB _ MAX 中的源代码。CPP)，它测试一个范围内的一些离散点，并找到具有最大函数值的点。如果该值在一个端点处增加，它会一直前进，直到找到一个峰值。然后在`brentmax()`(Brent max 中的源代码)中使用 Brent 的算法细化这个最大值。CPP)。不幸的是，这可能是一个昂贵的操作。但是回报往往是巨大的，特别是当差异进化已经让我们接近全局最大值，而我们所需要的只是最佳个体的精确最大化。

我们在参数的当前值附近开始粗略的全局搜索:

```cpp
               lower = local_base - 0.1 * (high_bounds[k] - low_bounds[k]) ;
               upper = local_base + 0.1 * (high_bounds[k] - low_bounds[k]) ;

               if (lower < low_bounds[k]) {
                  lower = low_bounds[k] ;
                  upper = low_bounds[k] + 0.2 * (high_bounds[k] - low_bounds[k]) ;
                  }

               if (upper > high_bounds[k]) {
                  upper = high_bounds[k] ;
                  lower = high_bounds[k] - 0.2 * (high_bounds[k] - low_bounds[k]) ;
                  }

               k = glob_max ( lower , upper , 7 , 0 , c_func ,
                              &x1 , &y1 , &x2 , &y2 , &x3 , &y3 ) ;

```

此时，我们有三个点，使得中心点具有最大函数值。对此进行细化，并调用`ensure_legal()`来确保参数在其合法范围内。很可能是这种情况，或者至少非常接近，因为当超过合法界限时，标准函数应用巨大的惩罚，并且最大化例程将对该惩罚做出有力的响应。如果性能已经得到改善，即使在强制合法性之后(这几乎总是会发生的情况)，保存高级参数并更新 grand best。最后，更新最差和平均性能，严格用于用户更新(不是算法的一部分)。

```cpp
               brentmax ( 5 , 1.e-8 , 0.0001 , c_func , &x1 , &x2 , &x3 , y2 ) ;
               dest_ptr[local_ivar] = x2 ;  // Optimized var value
               ensure_legal ( nvars , nints , low_bounds , high_bounds , dest_ptr ) ;
               value = criter ( dest_ptr , mintrades ) ;
               if (value > old_value) {
                  dest_ptr[nvars] = value ;
                  }
               else {
                  dest_ptr[local_ivar] = local_base ;       // Restore original value
                  value = old_value ;
                  }
               if (value > grand_best) {       // Update best so far
                  grand_best = value ;
                  memcpy ( best , dest_ptr , dim * sizeof(double) ) ;
                  ibest = ind ;
                  n_tweaked = 0 ;
                  improved = 1 ;   // Flag that the best improved in this generation
                  }
               } // If optimizing real parameter
            } // If doing hill-climbing step

         if (value < worstf)
            worstf = value ;

         avgf += value ;

         } // Create all children in this generation

```

我们差不多完成了。如果这一代发现最佳个体没有改进，则增加收敛计数器，如果达到用户指定的计数，则退出。但是如果我们真的得到了改善，重置计数器。然后针对源和目的地生成群体颠倒`pop1`和`pop2`的角色。剩下的少量代码只是清理工作，这里省略了。

```cpp
      if (! improved) {
         ++bad_generations ;
         if (bad_generations > max_bad_gen)
            goto FINISHED ;
         }
      else
         bad_generations = 0 ;

      if (old_gen == pop1) {
         old_gen = pop2 ;
         new_gen = pop1 ;
         }
      else {
         old_gen = pop1 ;
         new_gen = pop2 ;
         }

      } // For all generations

```

确保合法性的例程只是对照用户指定的限制检查每个参数，计算超出限制的严格惩罚(仅用于实际参数调整)，并强制执行限制。对于整数，我们分别对待正值和负值，以确保正确的截断。回想一下，突变通常会导致整数参数获得非整数值，所以我们在这里首先解决这个问题。

```cpp
static double ensure_legal ( int nvars , int nints , double *low_bounds , double
*high_bounds , double *params )
{
   int i, j, varnum, ilow, ihigh ;
   double rlow, rhigh, penalty, dtemp ;

   penalty = 0.0 ;

   for (i=0 ; i<nvars ; i++) {

      if (i < nints) {                   // Is this an integer parameter?
         if (params[i] >= 0)
            params[i] = (int) (params[i] + 0.5) ;
         else if (params[i] < 0)
            params[i] = -(int) (0.5 - params[i]) ;
         }

      if (params[i] > high_bounds[i]) {
         penalty += 1.e10 * (params[i] - high_bounds[i]) ;
         params[i] = high_bounds[i] ;
         }

      if (params[i] < low_bounds[i]) {
         penalty += 1.e10 * (low_bounds[i] - params[i]) ;
         params[i] = low_bounds[i] ;
         }
      }

   return penalty ;
}

```

由`glob_max()`和`brentmax()`调用的程序是被优化的单个参数的简单函数。将适当的参数设置为试验值，并调用`ensure_legal()`来执行合法性并计算超出界限的可能惩罚。然后调用性能计算例程来计算交易系统的性能，并且从性能中减去惩罚(如果有的话)。

```cpp
static double c_func ( double param )
{
   double penalty ;

   local_x[local_ivar] = param ;
   penalty = ensure_legal ( local_nvars , local_nints , local_low_bounds ,
                                           local_high_bounds , local_x ) ;
   return local_criter ( local_x , mintrades ) - penalty ;
}

```

一个完整的程序来演示这个算法。CPP 将在第 112 页介绍。